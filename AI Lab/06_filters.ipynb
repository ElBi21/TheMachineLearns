{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"><b>AI Lab: Computer Vision and NLP</b></h1>\n",
    "<h3 align=\"center\">Lecture 07: Filters</h3>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the purpouse of filters in CV? They are an operation which is done on images, such as blurring and so on...\n",
    "\n",
    "In order to apply a filter to an image, we use an operation called **convolution**. There are different types of convolutions:\n",
    " - 1D convolutions (for signals and so on...);\n",
    " - 2D convolutions (for images);\n",
    " - 3D convolutions;\n",
    " - and so on...\n",
    "\n",
    "The convolution is done via a matrix called kernel. It's done in the following way:\n",
    " 1. the matrix of the image is sliced into a sub-matrix;\n",
    " 2. each sub-matrix has as center a value of the original matrix: if the sub-matrix goes out of the range of the original matrix, the blank space is filled with the neighbour number;\n",
    " 3. the **dot product** is done between the two matrices:\n",
    "    $$ A_{\\{3, \\; 3\\}} \\cdot \\text{Kernel}_{\\{3, \\; 3\\}}$$\n",
    " 4. the result is placed on the location given by the beginning matrix.\n",
    "\n",
    "Let's begin by creating a kernel and applying it to an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We proceed now to read the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"imgs/04_imgs/gerry.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can either provide a kernel of our own or just use a pre-defined kernel. We want to create one first, so let's create a `numpy` array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_kernel = np.array([\n",
    "    [1, 0, 1],\n",
    "    [1, 0, 1],\n",
    "    [1, 0, 1]\n",
    "], np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's usually a good choice to use squared filters with an odd number of elements for each side, in order to easily find the center. Now, we can use the `cv2.filter2D()` function to apply a filter to the image:\n",
    "> ```Python\n",
    "> cv2.filter2D(image, channels, kernel)\n",
    "> ```\n",
    "> where:\n",
    ">  - `image` is the image on which we want to apply the filter;\n",
    ">  - `channels` is the number of channels on which we want to apply the filter. If the number is `-1`, then it's applied to all the channels;\n",
    ">  - `kernel` is the kernel that we want to apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_image = cv2.filter2D(image, -1, a_kernel)\n",
    "cv2.imwrite(\"imgs/04_imgs/gerry_filtered_1.png\", filtered_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![gerry_filtered_1](imgs/04_imgs/gerry_filtered_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why would we want to apply a filter on an image? Because they can be useful while trying to reduce the noise. The blur filter is one of the most effective filters when it comes down to reduce noise. `OpenCV` gives us a built-in function, `cv2.blur()`, which allows us to blur a given image given the size of the kernel. The bigger the kernel, the stronger the blur effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blurred_image = cv2.blur(image, (5, 5))\n",
    "cv2.imwrite(\"imgs/04_imgs/gerry_blurred_1.png\", blurred_image)\n",
    "\n",
    "blurred_image_2 = cv2.blur(image, (15, 15))\n",
    "cv2.imwrite(\"imgs/04_imgs/gerry_blurred_2.png\", blurred_image_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|`gerry_blurred_1.png`|`gerry_blurred_2.png`|\n",
    "|---|---|\n",
    "|![gerry_blur_1](imgs/04_imgs/gerry_blurred_1.png)|![gerry_blur_2](imgs/04_imgs/gerry_blurred_2.png)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also other types of blurs: `gaussianBlur()` and `medianBlur()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gauss_gerry = cv2.GaussianBlur(image, (7, 7), 0)\n",
    "cv2.imwrite(\"imgs/04_imgs/gerry_blurred_gaussian.png\", gauss_gerry)\n",
    "\n",
    "median_gerry = cv2.medianBlur(image, 15)\n",
    "cv2.imwrite(\"imgs/04_imgs/gerry_blurred_median.png\", median_gerry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|`gerry_blurred_gaussian.png`|`gerry_blurried_median.png`|\n",
    "|---|---|\n",
    "|![blurred_gaussian_gerry](imgs/04_imgs/gerry_blurred_gaussian.png)|![blurred_median_gerry](imgs/04_imgs/gerry_blurred_median.png)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also another type of filter, called bilateral filter. It can be use with the `cv2.bilateralFilter()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bilateral_gerry = cv2.bilateralFilter(image, 9, 75, 75)\n",
    "cv2.imwrite(\"imgs/04_imgs/gerry_filtered_2.png\", bilateral_gerry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|`gerry_filtered_2.png`|\n",
    "|---|\n",
    "|![gerry_bilateral](imgs/04_imgs/gerry_filtered_2.png)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filters can be used in order to sharpen the original image, starting from a blurred image. We'll use as a default the `gerry_blurred_gaussian.png` file, stored within the `gauss_gerry` variable. In order to sharpen an image, we can use the `cv2.addWeighted()` function, which adds together the blurred image and the original image, together with a weight. There is an additional parameter, called `gamma` $\\gamma$, which is used with colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sharped_gerry = cv2.addWeighted(image, 0.5, gauss_gerry, 0.5, 0)\n",
    "cv2.imwrite(\"imgs/04_imgs/gerry_sharped_1.png\", sharped_gerry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|`gerry_sharped_1.png`|\n",
    "|---|\n",
    "|![sharped_gerry](imgs/04_imgs/gerry_sharped_1.png)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "another_kernel = np.array([\n",
    "    [0, -1, 0],\n",
    "    [-1, 5, -1],\n",
    "    [0, -1, 0]\n",
    "], np.float32)\n",
    "\n",
    "sharped_with_kernel = cv2.filter2D(image, -1, another_kernel)\n",
    "cv2.imwrite(\"imgs/04_imgs/gerry_sharped_2.png\", sharped_with_kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also possible to extract contours from the image. There are two ways to do it, depending on the kernel used. The two used kernels are the **Sobel** kernel and the **Laplacian** kernel.\n",
    "\n",
    "How can we detect a contour? By taking the derivative of the image. Why do we use the derivative though? Let's jump to calculus for a bit: if we have a function, then in order to have a general idea of the function's behaviour we can take its derivative and study some specific points. And that's the same with images: whenever there is a high variability of pixel density, we can detect it with the derivative.\n",
    "\n",
    "The Sobel operator aims to compute the peak of the pixel density. It does it thanks to this computation:\n",
    "$$G_x \\; = \\; \\begin{bmatrix} \\end{bmatrix} \\cdot I$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGRA2GRAY)\n",
    "\n",
    "derivative_x = cv2.Sobel(image_gray, -1, 1, 0)\n",
    "derviative_y = cv2.Sobel(image_gray, -1, 0, 1)\n",
    "\n",
    "scaled_x = cv2.convertScaleAbs(derivative_x)\n",
    "scaled_y = cv2.convertScaleAbs(derviative_y)\n",
    "\n",
    "cv2.imwrite(\"imgs/04_imgs/gerry_derivated_x.png\", scaled_x)\n",
    "cv2.imwrite(\"imgs/04_imgs/gerry_derivated_y.png\", scaled_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|`gerry.png`|`gerry_derivated_x.png`|`gerry_derivated_y.png`|\n",
    "|---|---|---|\n",
    "|![gerry](imgs/04_imgs/gerry.png)|![gerry_der_x](imgs/04_imgs/gerry_derivated_x.png)|![gerry_der_y](imgs/04_imgs/gerry_derivated_y.png)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differently from the Sobel operator, the Laplacian operator computes the second derivative of the image. The second derivatives basically returns all the pixels that are 0, both from the second derivative and from the original image. It basically applies twice the Sobel operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "derivative = cv2.Laplacian(image_gray, -1, (3, 3))\n",
    "derivative_absolute = cv2.convertScaleAbs(derivative)\n",
    "\n",
    "cv2.imwrite(\"imgs/04_imgs/gerry_derivated_laplacian.png\", derivative_absolute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|`gerry.png`|`gerry_derivated_laplacian_.png`|\n",
    "|---|---|\n",
    "|![gerry](imgs/04_imgs/gerry.png)|![gerry_der_x](imgs/04_imgs/gerry_derivated_laplacian.png)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create, thanks to the filters that we did so far, a cartoon filter that can be applied to any image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bring the image to grayscale\n",
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Soft clean the image\n",
    "image_gray = cv2.medianBlur(image_gray, 5)\n",
    "\n",
    "# Use the Laplacian filter in order to extract the contours\n",
    "edges = cv2.Laplacian(image_gray, cv2.CV_8U, ksize=5)\n",
    "\n",
    "# Threshold the edges in order to get only some valid edges (so with value greater than 70)\n",
    "ret, threshold = cv2.threshold(edges, 70, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Now we can extract the colors. We can use the bilateral filter with high values, so that we can keep some edges\n",
    "color_image = cv2.bilateralFilter(image, 10, 250, 250)\n",
    "\n",
    "# Put together the two images, so the color and the sketch\n",
    "sketch = cv2.cvtColor(threshold, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "# Do the bitwise of the two images and merge the sketch and the color\n",
    "final_image = cv2.bitwise_and(color_image, sketch)\n",
    "\n",
    "cv2.imwrite(\"imgs/03_imgs/img02_cartoon.jpg\", final_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|`gerry.png`|`gerry_cartoon.png`|\n",
    "|---|---|\n",
    "|![gerry](imgs/04_imgs/gerry.png)|![gerry cartoon](imgs/04_imgs/gerry_cartoon.png)|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ailab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
