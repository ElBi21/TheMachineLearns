{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"><b>AI Lab: Computer Vision and NLP</b></h1>\n",
    "<h3 align=\"center\">Lecture 09: Histograms</h3>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histograms are a very powerful tool, which allows us to see various parameters of the image (if the image has enough light, if it's overexposed, etc...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fix eventual problems of colouring with some `cv2` functions, such as the `cv2.equalizeHist()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"imgs/04_imgs/gerry.png\")\n",
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray_eq = cv2.equalizeHist(image_gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[FILL WITH IMAGES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same with coloured images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = cv2.split(image)\n",
    "eq_channels = []\n",
    "\n",
    "for chann in channels:\n",
    "    eq_channels.append(cv2.equalizeHist(chann))\n",
    "\n",
    "equalized = cv2.merge(eq_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[FILL WITH IMAGES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how the result is pretty much a contrasting image: the colors have an high contrast, and the saturation is much lower. There is another way to equalize the colors in an image, and it's done via the manipulation of the **hue**, **saturation** and **value** of the color.\n",
    "\n",
    "The **hue** specifies the tone of the color, the **value** how much bright the color should be, the **saturation** the vivacity of the color.\n",
    "\n",
    "The colorspace given by these three values is called **HSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "hue, saturation, value = cv2.split(hsv_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to equalize just one channel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equalized_value = cv2.equalizeHist(value)\n",
    "equlaized = cv2.merge([hue, saturation, equalized_value])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the result seems to have some retrowave style, it's techincally equalized on the `value` channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an approach, called **CLAHE**, which is used to equalize the channels of an image **in grayscale only**. This approach uses an histogram of an image and aims to consider just a small portion of the image itself.\n",
    "\n",
    "Such approach can be used in the following way:\n",
    "> ```python\n",
    "> cv2.createCLAHE(\n",
    ">     clipLimit=cL,\n",
    ">     tileGridSize=(tx, ty)\n",
    ">     )\n",
    "> ```\n",
    "> where:\n",
    ">  - `clipLimit` defines an upper bound over which the histogram is computed (defined by `cL`);\n",
    ">  - `tileGridSize` defines the size of the sub-image (given by `(tx, ty)`) on which the equalization operation is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of CLAHE\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "\n",
    "equalized = clahe.apply(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ailab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
