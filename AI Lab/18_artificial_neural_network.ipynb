{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"><b>AI Lab: Computer Vision and NLP</b></h1>\n",
    "<h3 align=\"center\">Lessons 17-19: Artificial Neural Networks</h3>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our brain works with neurons, which are small cells which can retain data and make reasonments. Computer scientists have tried along the past years to replicate a human brain and thus allow a computer to have an artificial one. Since neurons work with small quantities of electricity, then such small pulses of energy could be translated with a binary pulse. One of the first applications of a neuron was to implement logic gates, such as the `AND` ($y = x_1 \\wedge x_2$) or the `OR` ($y = x_1 \\vee x_2$).\n",
    "\n",
    "An artificial neuron is very similar to a logic gate: with an `AND` gate with 2 inputs $x_1$ and $x_2$, we would have that the output $y$ is equal to 1 if, by summing the two inputs, we reach a threshold $T \\geq 2$. The neuron has, instead of a fixed threshold, a variable one. Such threshold represents thus the **activation function** of a neuron.\n",
    "\n",
    "We can compare how powerful tools such as `pytorch` are compared to other tools such as `scikit-learn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import fetch_openml, load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now proceed to load the dataset, and thanks to the passing of the option `return_X_y = true` we can tell `scikit-learn` to pass us the dataset already splitted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x, y = fetch_openml('mnist_784', return_X_y=True)\n",
    "digits = load_digits()\n",
    "x, y = digits.data, digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can create the test and train datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a multilevel perceptron (**MLP**), and with `scikit-learn` we can provide some hidden layers which are not considering the input and output layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(hidden_layer_sizes=(20,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leonardo/miniconda3/envs/ailab/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(20,))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MLPClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neural_network.MLPClassifier.html\">?<span>Documentation for MLPClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier(hidden_layer_sizes=(20,))</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(20,))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we can test the model and see how well it performs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Now, this was the version with `scikit-learn`. We said thought previously that `scikit-learn` runs only on CPUs, and this is not helpful while trying to train a large model. So we can use instead `pytorch`, and we can try to do it all over again from scratch. The problem with `pytorch` is that we have to do everything from scratch. In order to use `pytorch`, we start by importing the package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch import nn\n",
    "import torchmetrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import a dataset with some images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"pytorch_datasets\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor() # This function will transform the data into tensors,\n",
    "                         # we just need to specify the transformation function\n",
    ") # type: ignore\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"pytorch_datasets\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access to the dataset with the syntax\n",
    "```python\n",
    "image, label = data[index]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = training_data[25]\n",
    "plt.imshow(image.squeeze(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, here it comes the most important part: we have to fetch the GPU in order to use it instead of the CPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now start to create our multilevel perceptron. It's important to define meticulously the two methods of the MLP class: the `init` method contains the basis for the MLP, while the `forward` method passes the data to the next layer.\n",
    "\n",
    "The `nn.Sequential()` function is useful when creating the MLP because it allows to execute all the instructions inside such function sequentially. Within the `nn.Sequential()` function we have another function, `nn.Linear()`. Such function allows to define the input and output size in edges of our linear perceptron layer:\n",
    "\n",
    "$$\n",
    "\\text{size}(a_{\\text{in}}) \\; \\longrightarrow \\; \\text{size}(a_{\\text{out}})\n",
    "$$\n",
    "$$\n",
    "\\mathbb{R}^i \\; \\longmapsto \\; \\mathbb{R}^j\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurMLP(nn.Module):\n",
    "    def __init__(self, seq=True):\n",
    "        \"\"\"Parameters:\n",
    "            - `seq` (`True` by default): if True, it will load a sequential version of the MLP.\n",
    "                                         If false, it will load a non sequential version.\"\"\"\n",
    "        if seq:\n",
    "            super().__init__()\n",
    "            self.mlp = nn.Sequential(\n",
    "                # From this layer x we will export 50 edges to the next layer...\n",
    "                nn.Linear(28 * 28, 50),\n",
    "                nn.Sigmoid(),\n",
    "                # ...then from 50 to 100...\n",
    "                nn.Linear(50, 100),\n",
    "                nn.Sigmoid(),\n",
    "                # ...then from 100 to 50...\n",
    "                nn.Linear(100, 50),\n",
    "                nn.Sigmoid(),\n",
    "                # ...then from 50 to 120, and so on and so forth...\n",
    "                #nn.Linear(50, 120),\n",
    "                #nn.Sigmoid(),\n",
    "                #nn.Linear(120, 60),\n",
    "                #nn.Sigmoid(),\n",
    "                #nn.Linear(60, 50),\n",
    "                #nn.Sigmoid(),\n",
    "\n",
    "                # Output layer\n",
    "                nn.Linear(50, 10)\n",
    "            )\n",
    "            self.flatten = nn.Flatten()\n",
    "        else:\n",
    "            super().__init__()\n",
    "            self.input_layer = nn.Linear(28*28, 50)\n",
    "            self.hidden1 = nn.Linear(50, 100)\n",
    "            self.hidden2 = nn.Linear(100, 50)\n",
    "            self.hidden3 = nn.Linear(50, 120)\n",
    "            self.hidden4 = nn.Linear(120, 60)\n",
    "            self.hidden5 = nn.Linear(60, 50)\n",
    "            self.output_layer = nn.Linear(50, 10)\n",
    "            self.activation = nn.Sigmoid()\n",
    "            self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x, seq=True):\n",
    "        \"\"\"Parameters:\n",
    "            - `seq` (`True` by default): if True, it will load a sequential version of the MLP.\n",
    "                                         If false, it will load a non sequential version.\"\"\"\n",
    "        if seq:\n",
    "            x = self.flatten(x)\n",
    "            logits = self.mlp(x)\n",
    "            return logits\n",
    "        else:\n",
    "            x = self.input_layer(x)\n",
    "            x = self.activation(x)\n",
    "            x = self.flatten(x)\n",
    "            logits = self.mlp(x)\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we must instantiate the model by defining the hyperparameters and the optimizer. The optimizer is the function in charge of tuning the parameters of the model, so it computes the necessary derivatives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OurMLP().to(device)\n",
    "model_no_seq = OurMLP(seq=False).to(device)\n",
    "\n",
    "epochs = 2\n",
    "batch_size = 16\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# Loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer. We can use either SGD or AdamW, but AdamW is more performant than SGD\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to create the data loader, which is in charge of taking the data from the disk and give it to the `pytorch` model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get some metrics from the model's performances, thanks to the `torchmetrics` package. We are using the `multiclass` parameter because our model will label each object with only one label, assigning such object to one class only; with the `multilabel` parameter our model would've assigned one object to multiple classes, thus assigning multiple labels to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, finally, we define the training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, epoch=None, debug=True):\n",
    "    \"\"\"Trains an epoch of the model\n",
    "    \n",
    "    Parameters:\n",
    "        - `dataloader`: the dataloader of the dataset\n",
    "        - `model`: the model used\n",
    "        - `loss_fn`: the loss function of the model\n",
    "        - `optimizer`: the optimizer\n",
    "        - `epoch`: the index of the epoch\n",
    "    \"\"\"\n",
    "    size = len(dataloader)\n",
    "\n",
    "    # Get the batch from the dataset\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        # Move data to the device used\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # Compute the prediction and the loss\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Adjust the weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Print some information\n",
    "        if batch % 20 == 0:\n",
    "            loss_value, current_batch = loss.item(), (batch + 1) * len(x)\n",
    "            if debug: print(f\"→ Loss: {loss_value} [Batch {current_batch}/{size}, Epoch {epoch}/{epochs}]\")\n",
    "            accuracy = metric(pred, y)\n",
    "            if debug: print(f\"Accuracy of batch {current_batch}/{size}: {accuracy}\")\n",
    "        \n",
    "    accuracy = metric.compute()\n",
    "    print(f\"=== The epoch {epoch}/{epochs} has finished training ===\")\n",
    "    if debug: print(f\"→ Final accuracy of the epoch: {accuracy}\")\n",
    "    metric.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, this previous function is just the training loop for one epoch. We'll have to run it for all the epochs that we want to have. We now just need to define the test loop and we are ready to run the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn, debug=True):\n",
    "    size = len(dataloader)\n",
    "\n",
    "    # Disable the updating of the weights\n",
    "    with torch.no_grad():\n",
    "        for index, (x, y) in enumerate(dataloader):\n",
    "            # Move the data to the device used for testing\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # Get the model prediction\n",
    "            pred = model(x)\n",
    "\n",
    "            # Get the accuracy score\n",
    "            acc = metric(pred, y)\n",
    "            if debug: print(f\"→ Accuracy for image {index}: {acc}\")\n",
    "    acc = metric.compute()\n",
    "    print(f\"===    The testing loop has finished    ===\")\n",
    "    if debug: print(f\"→ Final testing accuracy of the model: {acc}\")\n",
    "    metric.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch_ind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      2\u001b[0m     train_loop(train_dataloader, model, loss_fn, optimizer, epoch_ind, debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m     test_loop(test_dataloader, model, loss_fn, debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'epochs' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch_ind in range(epochs):\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer, epoch_ind, debug=False)\n",
    "    test_loop(test_dataloader, model, loss_fn, debug=False)\n",
    "\n",
    "print(\"=== The training has finished ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also train a non sequential model. We just repeat the two previous steps with the non sequential model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'OurMLP' object has no attribute 'mlp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch_ind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m----> 2\u001b[0m     train_loop(train_dataloader, model_no_seq, loss_fn, optimizer, epoch_ind)\n\u001b[1;32m      4\u001b[0m test_loop(test_dataloader, model_no_seq, loss_fn)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=== The training has finished ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[18], line 20\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer, epoch, debug)\u001b[0m\n\u001b[1;32m     17\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Compute the prediction and the loss\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m pred \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[1;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, y)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Adjust the weights\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ailab/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ailab/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 42\u001b[0m, in \u001b[0;36mOurMLP.forward\u001b[0;34m(self, x, seq)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m seq:\n\u001b[1;32m     41\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten(x)\n\u001b[0;32m---> 42\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(x)\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logits\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/ailab/lib/python3.12/site-packages/torch/nn/modules/module.py:1688\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1687\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1688\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'OurMLP' object has no attribute 'mlp'"
     ]
    }
   ],
   "source": [
    "for epoch_ind in range(epochs):\n",
    "    train_loop(train_dataloader, model_no_seq, loss_fn, optimizer, epoch_ind, debug=False)\n",
    "    test_loop(test_dataloader, model_no_seq, loss_fn, debug=False)\n",
    "\n",
    "print(\"=== The training has finished ===\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ailab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
